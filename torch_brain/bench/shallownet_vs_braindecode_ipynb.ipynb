{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ShallowNet vs Braindecode ShallowFBCSPNet: Equivalence & Benchmark\n",
        "\n",
        "**Goal:** show our minimal `ShallowNet` is functionally equivalent to Braindecode’s `ShallowFBCSPNet`, and record timing.\n",
        "\n",
        "**Tests included**\n",
        "- Weight copy → output equality (assert_close)\n",
        "- Multi-batch randomized test (statistical)\n",
        "- Layer-by-layer diffs (diagnostic)\n",
        "- Cosine similarity (aggregate)\n",
        "- Micro-benchmark timing\n",
        "\n",
        "**Versions & seed**: recorded below for reproducibility.\n"
      ],
      "metadata": {
        "id": "SjPLRCnFw4MZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup & reproducibility"
      ],
      "metadata": {
        "id": "pFdbxt9k6GI3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TX6t3bAwu2h",
        "outputId": "7f0dd8f0-5655-4b44-b3b5-05bf97de4509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python : 3.11.13\n",
            "PyTorch: 2.6.0+cu124\n",
            "Device : cuda\n",
            "Braindecode available: True\n"
          ]
        }
      ],
      "source": [
        "import os, sys, time, math, json, platform, torch, numpy as np\n",
        "import torch.nn as nn\n",
        "from importlib import util\n",
        "\n",
        "# For deterministic-ish runs (note: may affect speed on CUDA)\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.float32\n",
        "\n",
        "print(\"Python :\", platform.python_version())\n",
        "print(\"PyTorch:\", torch.__version__)\n",
        "print(\"Device :\", device)\n",
        "\n",
        "# repo imports\n",
        "from torch_brain.models.shallownet import ShallowNet\n",
        "assert hasattr(ShallowNet, \"__call__\")\n",
        "\n",
        "# optional Braindecode import\n",
        "HAS_BD = util.find_spec(\"braindecode\") is not None\n",
        "print(\"Braindecode available:\", HAS_BD)\n",
        "if HAS_BD:\n",
        "    from braindecode.models import ShallowFBCSPNet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparams"
      ],
      "metadata": {
        "id": "6euQlsPw6B88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters to keep consistent across models\n",
        "B, C, T, K = 8, 22, 1000, 4\n",
        "f_time = 25\n",
        "nft = 40\n",
        "nfs = 40\n",
        "pool_len = 75\n",
        "pool_stride = 15\n",
        "drop = 0.5"
      ],
      "metadata": {
        "id": "RVLXcFHGzDtC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build models"
      ],
      "metadata": {
        "id": "0eV2M2kn5-rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Our model: set logsoftmax=False to compare logits (most BD builds emit logits)\n",
        "ours = ShallowNet(\n",
        "    in_chans=C, in_times=T, n_classes=K,\n",
        "    filter_time_length=f_time, n_filters_time=nft, n_filters_spat=nfs,\n",
        "    pool_time_length=pool_len, pool_time_stride=pool_stride,\n",
        "    final_conv_length=\"auto\", dropout_p=drop, logsoftmax=False\n",
        ").to(device).eval()\n",
        "\n",
        "print(\"our final_conv_length:\", ours.final_conv_length)\n",
        "\n",
        "if HAS_BD:\n",
        "    bd = ShallowFBCSPNet(\n",
        "        n_chans=C, n_times=T, n_outputs=K, final_conv_length=\"auto\",\n",
        "        n_filters_time=nft, filter_time_length=f_time,\n",
        "        n_filters_spat=nfs, pool_time_length=pool_len, pool_time_stride=pool_stride,\n",
        "        pool_mode=\"mean\", split_first_layer=True,\n",
        "        batch_norm=True, batch_norm_alpha=0.1, drop_prob=drop,\n",
        "    ).to(device).eval()\n",
        "\n",
        "    # detect if BD has LogSoftmax head (some versions do)\n",
        "    has_bd_logsoftmax = any(isinstance(m, nn.LogSoftmax) for _, m in bd.named_modules())\n",
        "    print(\"BD has LogSoftmax head:\", has_bd_logsoftmax)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idPoyJOazVNT",
        "outputId": "bba6c4a8-8a16-4637-9c71-44afcb9850d5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "our final_conv_length: 61\n",
            "BD has LogSoftmax head: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weight copy by suffix"
      ],
      "metadata": {
        "id": "qSCsuVP957MK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_weights_by_suffix(src_sd, dst_sd, mapping_suffix_to_dstkey):\n",
        "    # find unique source keys by suffix\n",
        "    suffix2key = {}\n",
        "    for suffix in mapping_suffix_to_dstkey:\n",
        "        matches = [k for k in src_sd if k.endswith(suffix)]\n",
        "        if len(matches) != 1:\n",
        "            raise RuntimeError(f\"Suffix '{suffix}' matched {len(matches)} keys: {matches}\")\n",
        "        suffix2key[suffix] = matches[0]\n",
        "\n",
        "    copied = []\n",
        "    for suffix, dst_key in mapping_suffix_to_dstkey.items():\n",
        "        src_key = suffix2key[suffix]\n",
        "        assert src_sd[src_key].shape == dst_sd[dst_key].shape, (src_key, src_sd[src_key].shape, dst_key, dst_sd[dst_key].shape)\n",
        "        dst_sd[dst_key] = src_sd[src_key].clone()\n",
        "        copied.append((src_key, \"→\", dst_key, tuple(dst_sd[dst_key].shape)))\n",
        "    return dst_sd, copied\n",
        "\n",
        "if HAS_BD:\n",
        "    src_sd = bd.state_dict()\n",
        "    dst_sd = ours.state_dict()\n",
        "    wanted = {\n",
        "        \"conv_time.weight\":       \"conv_time.weight\",\n",
        "        \"conv_time.bias\":         \"conv_time.bias\",\n",
        "        \"conv_spat.weight\":       \"conv_spat.weight\",\n",
        "        \"bnorm.weight\":           \"bn.weight\",\n",
        "        \"bnorm.bias\":             \"bn.bias\",\n",
        "        \"bnorm.running_mean\":     \"bn.running_mean\",\n",
        "        \"bnorm.running_var\":      \"bn.running_var\",\n",
        "        \"conv_classifier.weight\": \"conv_classifier.weight\",\n",
        "        \"conv_classifier.bias\":   \"conv_classifier.bias\",\n",
        "    }\n",
        "    dst_sd, copied = copy_weights_by_suffix(src_sd, dst_sd, wanted)\n",
        "    ours.load_state_dict(dst_sd, strict=True)\n",
        "    print(\"Copied params:\")\n",
        "    for row in copied: print(\" \", row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x48jtkoDzqNC",
        "outputId": "e5f124b4-be28-4518-baab-ee4f1015fbdd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied params:\n",
            "  ('conv_time_spat.conv_time.weight', '→', 'conv_time.weight', (40, 1, 25, 1))\n",
            "  ('conv_time_spat.conv_time.bias', '→', 'conv_time.bias', (40,))\n",
            "  ('conv_time_spat.conv_spat.weight', '→', 'conv_spat.weight', (40, 40, 1, 22))\n",
            "  ('bnorm.weight', '→', 'bn.weight', (40,))\n",
            "  ('bnorm.bias', '→', 'bn.bias', (40,))\n",
            "  ('bnorm.running_mean', '→', 'bn.running_mean', (40,))\n",
            "  ('bnorm.running_var', '→', 'bn.running_var', (40,))\n",
            "  ('final_layer.conv_classifier.weight', '→', 'conv_classifier.weight', (4, 40, 61, 1))\n",
            "  ('final_layer.conv_classifier.bias', '→', 'conv_classifier.bias', (4,))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single-batch equivalence"
      ],
      "metadata": {
        "id": "5xMCfth452a_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if HAS_BD:\n",
        "    x = torch.randn(B, C, T, device=device, dtype=dtype)\n",
        "    with torch.no_grad():\n",
        "        y_me = ours(x)                          # logits\n",
        "        y_bd = bd(x)\n",
        "        if has_bd_logsoftmax:\n",
        "            # compare in log-probability space if BD ends with logsoftmax\n",
        "            y_me = y_me.log_softmax(dim=1)\n",
        "\n",
        "    max_abs = (y_me - (y_bd if not has_bd_logsoftmax else y_bd)).abs().max().item()\n",
        "    print(\"max abs diff:\", max_abs)\n",
        "    torch.testing.assert_close(y_me, y_bd if not has_bd_logsoftmax else y_bd, rtol=1e-4, atol=1e-5)\n",
        "    print(\"Functional match on single batch\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUNLnEKzz2AQ",
        "outputId": "2653b433-325e-429e-be6b-2177b5714db9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max abs diff: 7.62939453125e-06\n",
            "Functional match on single batch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-batch randomized stress test"
      ],
      "metadata": {
        "id": "33mn3EUS5zbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if HAS_BD:\n",
        "    fails = 0\n",
        "    for i in range(50):\n",
        "        x = torch.randn(B, C, T, device=device, dtype=dtype)\n",
        "        with torch.no_grad():\n",
        "            a = ours(x)\n",
        "            b = bd(x)\n",
        "            if has_bd_logsoftmax:\n",
        "                a = a.log_softmax(dim=1)\n",
        "        try:\n",
        "            torch.testing.assert_close(a, b, rtol=1e-4, atol=1e-5)\n",
        "        except AssertionError:\n",
        "            fails += 1\n",
        "            if fails < 3:\n",
        "                print(f\"[warn] batch {i} failed equality\")\n",
        "    print(f\"Multi-batch equality failures: {fails}/50 (expect 0)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-vQhfSV0n7Y",
        "outputId": "2e074ec9-46d9-4a08-ed64-28e898b9ff9e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-batch equality failures: 0/50 (expect 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layer-by-layer diff (diagnostic)"
      ],
      "metadata": {
        "id": "r3Oc524Q5dhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def tap(mod, name, bucket):\n",
        "    def hook(_, __, out):\n",
        "        bucket[name] = out.detach().cpu()\n",
        "    return mod.register_forward_hook(hook)\n",
        "\n",
        "def find_bd_module_by_suffix(root, suffix):\n",
        "    matches = [(n, m) for n, m in root.named_modules() if n.endswith(suffix)]\n",
        "    if len(matches) == 0:\n",
        "        print(f\"[WARN] No BD module endswith '{suffix}'. Available sample names:\")\n",
        "        print([n for n, _ in list(root.named_modules())[:25]])\n",
        "        return None, None\n",
        "    if len(matches) > 1:\n",
        "        print(f\"[WARN] Multiple BD modules end with '{suffix}': {[n for n,_ in matches]}. Using the last.\")\n",
        "    return matches[-1]  # (name, module)\n",
        "\n",
        "# --- our model points (direct attributes) ---\n",
        "ours_points = {\n",
        "    \"conv_time\": ours.conv_time,\n",
        "    \"conv_spat\": ours.conv_spat,\n",
        "    \"bn\":        ours.bn,\n",
        "    \"pool\":      ours.pool,\n",
        "    \"clf\":       ours.conv_classifier,\n",
        "}\n",
        "\n",
        "# --- braindecode points (found by suffix) ---\n",
        "bd_points = {}\n",
        "for key, suf in {\n",
        "    \"conv_time\": \"conv_time\",\n",
        "    \"conv_spat\": \"conv_spat\",\n",
        "    \"bn\":        \"bnorm\",\n",
        "    \"pool\":      \"pool\",\n",
        "    \"clf\":       \"conv_classifier\",\n",
        "}.items():\n",
        "    name, mod = find_bd_module_by_suffix(bd, suf)\n",
        "    if mod is not None:\n",
        "        bd_points[key] = mod\n",
        "        print(f\"[MAP] BD '{key}' -> '{name}'\")\n",
        "\n",
        "# --- register hooks ---\n",
        "ours_outs, bd_outs, handles = {}, {}, []\n",
        "for name, mod in ours_points.items():\n",
        "    handles.append(tap(mod, f\"ours:{name}\", ours_outs))\n",
        "for name, mod in bd_points.items():\n",
        "    handles.append(tap(mod, f\"bd:{name}\", bd_outs))\n",
        "\n",
        "# --- run forward once ---\n",
        "ours.eval(); bd.eval()\n",
        "with torch.no_grad():\n",
        "    _ = ours(x)   # x already defined earlier\n",
        "    _ = bd(x)\n",
        "\n",
        "# --- clean up hooks ---\n",
        "for h in handles: h.remove()\n",
        "\n",
        "# --- compare only keys that exist in both dicts ---\n",
        "# normalize keys back to plain names (\"ours:conv_time\" -> \"conv_time\")\n",
        "ours_norm = {k.split(\"ours:\",1)[-1]: v for k, v in ours_outs.items()}\n",
        "bd_norm   = {k.split(\"bd:\",1)[-1]  : v for k, v in bd_outs.items()}\n",
        "\n",
        "common = sorted(set(ours_norm.keys()) & set(bd_norm.keys()))\n",
        "if not common:\n",
        "    print(\"[WARN] No common tapped layers. Our keys:\", list(ours_norm.keys()), \"BD keys:\", list(bd_norm.keys()))\n",
        "else:\n",
        "    for k in common:\n",
        "        a, b = ours_norm[k], bd_norm[k]\n",
        "        mxd = (a - b).abs().max().item()\n",
        "        print(f\"{k:10s} | {tuple(a.shape)} vs {tuple(b.shape)} | max|Δ|={mxd:.3g}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCjv6FL31CUb",
        "outputId": "6ac4996c-6a0d-4f2f-da93-b098e081302b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MAP] BD 'conv_time' -> 'conv_time_spat.conv_time'\n",
            "[MAP] BD 'conv_spat' -> 'conv_time_spat.conv_spat'\n",
            "[MAP] BD 'bn' -> 'bnorm'\n",
            "[MAP] BD 'pool' -> 'pool'\n",
            "[MAP] BD 'clf' -> 'final_layer.conv_classifier'\n",
            "bn         | (8, 40, 976, 1) vs (8, 40, 976, 1) | max|Δ|=1.55e-06\n",
            "clf        | (8, 4, 1, 1) vs (8, 4, 1, 1) | max|Δ|=7.39e-06\n",
            "pool       | (8, 40, 61, 1) vs (8, 40, 61, 1) | max|Δ|=1.34e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cosine similarity (aggregate)"
      ],
      "metadata": {
        "id": "U541b2Wt5lSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if HAS_BD:\n",
        "    x = torch.randn(128, C, T, device=device, dtype=dtype)\n",
        "    with torch.no_grad():\n",
        "        a = ours(x)\n",
        "        b = bd(x)\n",
        "        if has_bd_logsoftmax:\n",
        "            a = a.log_softmax(dim=1)\n",
        "    cos = torch.nn.functional.cosine_similarity(a.flatten(), b.flatten(), dim=0).item()\n",
        "    cos = max(min(cos, 1.0), -1.0)\n",
        "    print(\"cosine similarity:\", cos)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_Bd5gxG4IEm",
        "outputId": "5abe0ed8-e24c-41f7-9369-dea750f63cf9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cosine similarity: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary"
      ],
      "metadata": {
        "id": "X3RD4lkL8937"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configuration**\n",
        "\n",
        "- final_conv_length (ours): 61 — matches analytic derivation with default parameters.\n",
        "\n",
        "- Architecture Match: Layer shapes align; naming differences account for missing conv_time / conv_spat capture in hooks.\n",
        "\n",
        "**Functional Match**\n",
        "\n",
        "Single-batch check:\n",
        "\n",
        "-  Max absolute difference: 7.6293e-06\n",
        " -> Matches within tolerance (rtol=1e-4, atol=1e-5).\n",
        "\n",
        "Multi-batch stress test (50 runs):\n",
        "\n",
        "- Failures: 0/50 — no instability detected.\n",
        "\n",
        "Cosine similarity (128 examples):\n",
        "\n",
        "- Value: 1.0 (tiny rounding variation ~1.0000001).\n",
        "\n",
        "**Layer-by-Layer Max |Δ|**\n",
        "\n",
        "*(Missing conv_time / conv_spat due to naming differences)*\n",
        "\n",
        "- bn: (8, 40, 976, 1) vs (8, 40, 976, 1) → 1.55e-06\n",
        "\n",
        "- pool: (8, 40, 61, 1) vs (8, 40, 61, 1) → 1.34e-07\n",
        "\n",
        "- classifier: (8, 4, 1, 1) vs (8, 4, 1, 1) → 7.39e-06\n",
        "\n",
        "All differences are well within expected tolerance.\n",
        "\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "- Functional Equivalence: Confirmed. Outputs match Braindecode’s to within floating-point tolerance.\n",
        "\n",
        "- Numerical Stability: Excellent. Differences are negligible and reproducible across runs."
      ],
      "metadata": {
        "id": "ch_14tpL38Ts"
      }
    }
  ]
}